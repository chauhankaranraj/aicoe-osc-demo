{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will curate the data and output them as SQuAD-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import config\n",
    "from src.data.s3_communication import S3Communication, S3FileType\n",
    "from src.components.preprocessing.kpi_inference_curator import TextKPIInferenceCurator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Extracted Text in SQUAD formmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kpi_id</th>\n",
       "      <th>question</th>\n",
       "      <th>sectors</th>\n",
       "      <th>add_year</th>\n",
       "      <th>kpi_category</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>What is the company name?</td>\n",
       "      <td>OG, CM, CU</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>OG, CM, CU</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>What is the total volume of proven and probabl...</td>\n",
       "      <td>OG</td>\n",
       "      <td>True</td>\n",
       "      <td>TEXT, TABLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1</td>\n",
       "      <td>What is the volume of estimated proven hydroca...</td>\n",
       "      <td>OG</td>\n",
       "      <td>True</td>\n",
       "      <td>TEXT, TABLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>What is the volume of estimated probable hydro...</td>\n",
       "      <td>OG</td>\n",
       "      <td>True</td>\n",
       "      <td>TEXT, TABLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kpi_id                                           question     sectors  \\\n",
       "0     0.0                          What is the company name?  OG, CM, CU   \n",
       "1     1.0  In which year was the annual report or the sus...  OG, CM, CU   \n",
       "2     2.0  What is the total volume of proven and probabl...          OG   \n",
       "3     2.1  What is the volume of estimated proven hydroca...          OG   \n",
       "4     2.2  What is the volume of estimated probable hydro...          OG   \n",
       "\n",
       "   add_year kpi_category  Unnamed: 5  Unnamed: 6  \n",
       "0     False         TEXT         NaN         NaN  \n",
       "1     False         TEXT         NaN         NaN  \n",
       "2      True  TEXT, TABLE         NaN         NaN  \n",
       "3      True  TEXT, TABLE         NaN         NaN  \n",
       "4      True  TEXT, TABLE         NaN         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_df = s3c.download_df_from_s3(\n",
    "    \"aicoe-osc-demo/kpi_mapping\",\n",
    "    \"kpi_mapping.csv\",\n",
    "    filetype=S3FileType.CSV,\n",
    "    header=0,\n",
    ")\n",
    "kpi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_folder': PosixPath('/opt/app-root/src/aicoe-osc-demo/data/annotations'),\n",
       " 'agg_annotation': PosixPath('/opt/app-root/src/aicoe-osc-demo/data/20201030 1Qbit aggregated_annotations_needs_correction.xlsx'),\n",
       " 'extracted_text_json_folder': PosixPath('/opt/app-root/src/aicoe-osc-demo/data/extraction'),\n",
       " 'output_squad_folder': PosixPath('/opt/app-root/src/aicoe-osc-demo/data/squad'),\n",
       " 'relevant_text_path': PosixPath('/opt/app-root/src/aicoe-osc-demo/data/infer_relevance/*.csv')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TextKPIInferenceCurator_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/src/components/preprocessing/kpi_inference_curator.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_single.loc[:,'source_page'] = df_single['source_page'].apply(lambda x: x[0])\n",
      "/opt/app-root/lib64/python3.8/site-packages/src/components/preprocessing/kpi_inference_curator.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_single.loc[:,'relevant_paragraphs'] = df['relevant_paragraphs'].apply(lambda x: x[0])\n"
     ]
    }
   ],
   "source": [
    "tkpi = TextKPIInferenceCurator(\n",
    "    **config.TextKPIInferenceCurator_kwargs,\n",
    "    kpi_df=kpi_df,\n",
    "    columns_to_read=config.TRAIN_KPI_INFERENCE_COLUMNS_TO_READ,\n",
    ")\n",
    "train_squad, val_squad = tkpi.curate(**config.CurateConfig().__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the data in SQuAD format, which is ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kpi_train.json\t      kpi_val_split.json\n",
      "kpi_train_split.json  reference_kpi_01-06-2022.csv\n"
     ]
    }
   ],
   "source": [
    "# see that the data has been curated and placed in the output folder\n",
    "output_dir = str(config.TextKPIInferenceCurator_kwargs['output_squad_folder'])\n",
    "!ls $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following shows how to train a kpi extraction model and make inference using that. <br> <br>\n",
    "KPI extraction model is a Question-Answering (QA) system. A public dataset for the Question-Answering task is called SQuAD. This notebook assumes that the ESG data is already curated in a SQuAD-like format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline includes components that are provided by the FARM library. FARM is a framework which facilitates transfer learning tasks for BERT based models. Documentation for FARM is available here: https://farm.deepset.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General imports\n",
    "import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set the configurable parameters. \n",
    "Before start training, parameters for each component of the training pipeline must be set. For this we create `config` objects which hold these parameters. Default values have already been set but they can be easily changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/01/2022 22:50:13 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from src.models.qa_farm_trainer import QAFARMTrainer\n",
    "from config_qa_farm_train import (\n",
    "    QAFileConfig,\n",
    "    QATokenizerConfig,\n",
    "    QAProcessorConfig,\n",
    "    QAModelConfig,\n",
    "    QATrainingConfig,\n",
    "    QAMLFlowConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = QAFileConfig(\"demo_train_kpi_infer\") #Settings data files and checkpoints parameters\n",
    "processor_config = QAProcessorConfig(\"demo_train_kpi_infer\") #Settings for the processor component\n",
    "tokenizer_config = QATokenizerConfig(\"demo_train_kpi_infer\") #Settings for the tokenizer\n",
    "model_config = QAModelConfig(\"demo_train_kpi_infer\") #Settings for the model\n",
    "train_config = QATrainingConfig(\"demo_train_kpi_infer\") #Settings for training\n",
    "mlflow_config = QAMLFlowConfig(\"demo_train_kpi_infer\") #Settings for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters can be changed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config.experiment_name = \"demo_train_kpi_infer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we advise that you manually update the parameters in the corresponding config file:\n",
    "\n",
    "`model_pipeline/model_pipeline/config_qa_farm_trainer.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should change the training data file to the one we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_data_path = os.path.join(output_dir, 'esg_kpi_train_15-10-2020.json')\n",
    "file_config.update_paths(output_dir, curated_data_path)\n",
    "file_config.perform_splitting = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the value for some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_name: \n",
      " demo_train_kpi_infer \n",
      "\n",
      "Data directory: \n",
      " /opt/app-root/src/aicoe-osc-demo/data \n",
      "\n",
      "Curated dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo/data/squad/kpi_train.json \n",
      "\n",
      "Split train/validation ratio: \n",
      "0.2 \n",
      "\n",
      "Training dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo/data/squad/kpi_train_split.json \n",
      "\n",
      "Validation dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo/data/squad/kpi_val_split.json \n",
      "\n",
      "Directory where trained model is saved: \n",
      " /opt/app-root/src/aicoe-osc-demo/models/KPI_EXTRACTION \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Experiment_name: \\n {file_config.experiment_name} \\n\")\n",
    "print(f\"Data directory: \\n {file_config.data_dir} \\n\")\n",
    "print(f\"Curated dataset path: \\n {file_config.curated_data} \\n\")\n",
    "print(f\"Split train/validation ratio: \\n{file_config.dev_split} \\n\")\n",
    "print(f\"Training dataset path: \\n {file_config.train_filename} \\n\")\n",
    "print(f\"Validation dataset path: \\n {file_config.dev_filename} \\n\")\n",
    "print(f\"Directory where trained model is saved: \\n {file_config.saved_models_dir} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens per example: 384 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max number of tokens per example: {processor_config.max_seq_len} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Use GPU: {train_config.use_cuda} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_rate: 2e-05 \n",
      "\n",
      "Number of epochs for fine tuning: 1 \n",
      "\n",
      "Batch size: 4 \n",
      "\n",
      "Perform Cross validation: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Learning_rate: {train_config.learning_rate} \\n\")\n",
    "print(f\"Number of epochs for fine tuning: {train_config.n_epochs} \\n\")\n",
    "print(f\"Batch size: {train_config.batch_size} \\n\")\n",
    "print(f\"Perform Cross validation: {train_config.run_cv} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training pipeline recieves the curated ESG dataset for KPI extraction. The necassary components includes the Tokenizer and Processor are loaded. These components will create features from the input text. Next, the model will be defined, the model is a bert-based model with extra dense layers for the question answering task. The weights of the model are initialized from the pretrained model on SQuAD dataset. In the Training phase the model will be fine-tuned on the ESG curated data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune on curated ESG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the parameters are set, a `QAFARMTrainer` object can be instantiated by passing all the configuration objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_trainer = QAFARMTrainer(\n",
    "    file_config=file_config,\n",
    "    tokenizer_config=tokenizer_config,\n",
    "    model_config=model_config,\n",
    "    processor_config=processor_config,\n",
    "    training_config=train_config,\n",
    "    mlflow_config=mlflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the method `run()` to start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_ For the first time, loading the model will take a little longer, for download the checkpoints. The model will be cached after that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_9549/822982082.py\u001b[0m(2)\u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 2 \u001b[0;31m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;31m# b /opt/app-root/lib64/python3.8/site-packages/src/models/farm_trainer.py:427\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0mfarm_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "pdb.set_trace()\n",
    "# b /opt/app-root/lib64/python3.8/site-packages/src/models/farm_trainer.py:427\n",
    "farm_trainer.run(metric = \"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the training process, the model and the processor vocabulary are saved into the directory `file_config.saved_models_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(os.path.join(config.ROOT, \"models\", \"KPI_EXTRACTION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al $file_config.saved_models_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the developement dataset at `file_config.dev_filename`. This dataset has not been seen by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config.dev_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the saved model and test it on some real examples.<br><br>\n",
    "First let's load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farm.infer import QAInferencer\n",
    "model = QAInferencer.load(file_config.saved_models_dir, batch_size=40, gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make prediction on a pair of paragraph and question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"the paris agreement on climate change drafted in 2015 aims to reduce worldwide emissions of greenhouse \n",
    "gases to a level intended to limit a rise in global temperatures to below 2 degrees or, better still,\n",
    "to below 1.5 degrees. verbundâ€™s target of reducing greenhouse gas emissions by 90% measured beginning from \n",
    "the basis year 2011 5 million tonnes co2e until 2021 includes scope 1, scope 2 market- based and parts of scope 3 emissions \n",
    "for energy and air travel. the science based targets initiative validated this goal as science-based in october 2016, \n",
    "i.e. it meets global standards. according to current planning, the target can be achieved. \n",
    "however, if the grid operator requires higher generation volumes \n",
    "\"\"\"\n",
    "question = \"What is the target year for climate commitment?\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_input = [\n",
    "        {\n",
    "            \"qas\": [question],\n",
    "            \"context\":  context\n",
    "        }]\n",
    "\n",
    "result = model.inference_from_dicts(dicts=QA_input)[0]\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the prediction result show? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the best answer. Generally it can be span-based or it can be no-answer, which ever is higher\n",
    "# Here the top answer is the span '2021'\n",
    "result['predictions'][0]['answers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-answerable score: The model is pretty confident that the answer to the question can be in the context.\n",
    "result['predictions'][0]['answers'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make the prediction on a squad-format file as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from farm.data_handler.utils import write_squad_predictions\n",
    "\n",
    "results = model.inference_from_file(file=file_config.dev_filename, return_json=False)\n",
    "result_squad = [x.to_squad_eval() for x in results]\n",
    "\n",
    "write_squad_predictions(\n",
    "    predictions=result_squad,\n",
    "    predictions_filename=file_config.dev_filename,\n",
    "    out_filename=os.path.join(file_config.data_dir, \"predictions.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is written in the `out_filename`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tip_: Many of the result objects belong to farm classes. If you want to see the attributes of its class in jupyter notebook, type the \"objectname.\" and then press tap. For example, try it in the below cell by pressing tap and see the attribiues of the class. This is an usefull jupyter notebook trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the cursor after dot and press Tab.\n",
    "result[0]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
